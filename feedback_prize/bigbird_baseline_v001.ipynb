{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PITT-_SDoeF"
      },
      "source": [
        "# BigBird Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glT0yBkNDoeG"
      },
      "source": [
        "Kake - 02/10  \n",
        "Bigbird based model\n",
        "\n",
        "**Reference:**  \n",
        "Articles: [BigBird論文](https://arxiv.org/abs/2007.14062),   \n",
        "　　　　[BERT論文](https://arxiv.org/abs/1810.04805) ([日本語要約](https://qiita.com/omiita/items/72998858efc19a368e50))  \n",
        "HuggingFace: https://huggingface.co/google/bigbird-roberta-base  \n",
        "SourseCode: https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-02-09T12:35:12.391106Z",
          "iopub.status.busy": "2022-02-09T12:35:12.390771Z",
          "iopub.status.idle": "2022-02-09T12:35:12.396633Z",
          "shell.execute_reply": "2022-02-09T12:35:12.396036Z",
          "shell.execute_reply.started": "2022-02-09T12:35:12.391069Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqfcb0jFDoeH",
        "outputId": "398e1329-f6d4-4991-f277-b218f5e9d825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Loading Libraries\n",
            "=======Versions=======\n",
            "Python: 3.7.12 (default, Jan 15 2022, 18:48:18) \n",
            "[GCC 7.5.0]\n",
            "NumPy: 1.19.5\n",
            "PyTorch: 1.10.0+cu111\n",
            "Transformers: 4.16.2\n"
          ]
        }
      ],
      "source": [
        "%reset -f\n",
        "\n",
        "import os, sys, tqdm, sklearn, sklearn.metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch, torch.utils\n",
        "import transformers\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "print(\"Done Loading Libraries\")\n",
        "print(\"Versions\".center(22, \"=\"))\n",
        "print(f\"Python: {sys.version}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkdy06reDoeI"
      },
      "source": [
        "## 1. modelのダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7BwXBzwDoeI"
      },
      "source": [
        "モデルパラメータがローカルに存在しない時に、HuggingFaceからダウンロードする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-09T12:38:00.110892Z",
          "iopub.status.busy": "2022-02-09T12:38:00.110581Z",
          "iopub.status.idle": "2022-02-09T12:38:00.115509Z",
          "shell.execute_reply": "2022-02-09T12:38:00.114726Z",
          "shell.execute_reply.started": "2022-02-09T12:38:00.110850Z"
        },
        "trusted": true,
        "id": "dSb_8j7nDoeI"
      },
      "outputs": [],
      "source": [
        "DOWNLOADED_MODEL_PATH = \"/content/model/bigbird_001\"\n",
        "MODEL_NAME = 'google/bigbird-roberta-base'\n",
        "if DOWNLOADED_MODEL_PATH == None:\n",
        "    DOWNLOADED_MODEL_PATH = \"models\"\n",
        "if DOWNLOADED_MODEL_PATH == \"models\":\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "    # tokenizerのダウンロード\n",
        "    # tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
        "    # tokenizer.save_pretrained(\"models\")\n",
        "\n",
        "    # configのダウンロード\n",
        "    config_model = transformers.AutoConfig.from_pretrained(MODEL_NAME)\n",
        "    config_model.num_labels = 15\n",
        "    config_model.save_pretrained(\"models\")\n",
        "\n",
        "    # model weightのダウンロード\n",
        "    backbone = transformers.AutoModelForTokenClassification.from_pretrained(MODEL_NAME, config=config_model)\n",
        "    backbone.save_pretrained(\"models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "Rml17r71DoeJ"
      },
      "outputs": [],
      "source": [
        "config = {'model_name': MODEL_NAME,   \n",
        "         'max_length': 1024,\n",
        "         'train_batch_size':4,\n",
        "         'valid_batch_size':4,\n",
        "         'epochs':5,\n",
        "         'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
        "         'max_grad_norm':10}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvgwPtiPDoeJ"
      },
      "source": [
        "## 2. DatasetとDataLoaderの準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3nSFf_hDoeJ"
      },
      "source": [
        "### DataをDataframeで読み込む"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_df = pd.read_csv(\"./data/train.csv\")"
      ],
      "metadata": {
        "id": "SYmd5wqMHRZu"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L_5cFb9DoeK"
      },
      "source": [
        "### TrainSetをNERラベルに置き換える"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA_F9-zRDoeK"
      },
      "source": [
        "それぞれの単語がどの役割を持つかのラベル  \n",
        "すでにファイルが存在するときはそれを読み込むだけ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "vpZChImqDoeL",
        "outputId": "b3bb56f7-9284-4db7-b994-c4c4cf34b15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15594, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-616f8fcf-eb95-43a4-a095-a2b8e74a2c1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3321A3E87AD3</td>\n",
              "      <td>I do agree that some students would benefit fr...</td>\n",
              "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DFEAEC512BAB</td>\n",
              "      <td>Should students design a summer project for sc...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, B-Position, I-Positio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2E4AFCD3987F</td>\n",
              "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
              "      <td>[O, O, O, O, B-Position, I-Position, I-Positio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EB6C2AF20BFE</td>\n",
              "      <td>People sometimes have a different opinion than...</td>\n",
              "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A91A08E523D5</td>\n",
              "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
              "      <td>[O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616f8fcf-eb95-43a4-a095-a2b8e74a2c1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-616f8fcf-eb95-43a4-a095-a2b8e74a2c1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-616f8fcf-eb95-43a4-a095-a2b8e74a2c1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             id  ...                                           entities\n",
              "0  3321A3E87AD3  ...  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...\n",
              "1  DFEAEC512BAB  ...  [O, O, O, O, O, O, O, O, B-Position, I-Positio...\n",
              "2  2E4AFCD3987F  ...  [O, O, O, O, B-Position, I-Position, I-Positio...\n",
              "3  EB6C2AF20BFE  ...  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...\n",
              "4  A91A08E523D5  ...  [O, O, B-Lead, I-Lead, I-Lead, I-Lead, I-Lead,...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "LOAD_TOKEN_FROM = \"./data\"\n",
        "if not LOAD_TOKEN_FROM:\n",
        "    all_entities = []\n",
        "    for k, items in enumerate(train_text_df.iterrows()):\n",
        "        # NERラベルのないダミーラベルを作る\n",
        "        total = items[1][\"text\"].split().__len__()\n",
        "        entities = [\"O\"]*total\n",
        "\n",
        "        for j in train_label_df[train_label_df[\"id\"] == items[1][\"id\"]].iterrows():\n",
        "            # discourseタイプを読み込む\n",
        "            discourse = j[1][\"discourse_type\"]\n",
        "            list_idx = [int(x) for x in j[1][\"predictionstring\"].split(\" \")]\n",
        "\n",
        "            # 開始タグをつける\n",
        "            entities[list_idx[0]] = f\"B-{discourse}\"\n",
        "\n",
        "            for k in list_idx[1:]:\n",
        "                entities[k] = f\"I-{discourse}\"\n",
        "        all_entities.append(entities)\n",
        "    train_text_df[\"entities\"] = all_entities\n",
        "    train_text_df.to_csv(\"./data/train_NER.csv\", index=False)\n",
        "else:\n",
        "    from ast import literal_eval\n",
        "    train_text_df = pd.read_csv(f\"{LOAD_TOKEN_FROM}/train_NER.csv\")\n",
        "    train_text_df.entities = train_text_df.entities.apply(lambda x: literal_eval(x))\n",
        "print(train_text_df.shape)\n",
        "train_text_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG2Dg-LHDoeL"
      },
      "source": [
        "token化するためのlookup辞書を作る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "y4WYMlPXDoeM"
      },
      "outputs": [],
      "source": [
        "lookups = ['O', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', 'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\n",
        "\n",
        "labels_to_ids = {v:k for k, v in enumerate(lookups)}\n",
        "ids_to_labels = {k:v for k, v in enumerate(lookups)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFiBMPhbDoeM",
        "outputId": "ffe46dd5-65c2-4fc3-f066-bc3144914a9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-Claim': 5,\n",
              " 'B-Concluding Statement': 13,\n",
              " 'B-Counterclaim': 7,\n",
              " 'B-Evidence': 11,\n",
              " 'B-Lead': 1,\n",
              " 'B-Position': 3,\n",
              " 'B-Rebuttal': 9,\n",
              " 'I-Claim': 6,\n",
              " 'I-Concluding Statement': 14,\n",
              " 'I-Counterclaim': 8,\n",
              " 'I-Evidence': 12,\n",
              " 'I-Lead': 2,\n",
              " 'I-Position': 4,\n",
              " 'I-Rebuttal': 10,\n",
              " 'O': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "labels_to_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQH-9v1VDoeM"
      },
      "source": [
        "### Datasetクラスの実装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN5Mh3W_DoeM"
      },
      "source": [
        "PyTorchで実装しているためDatasetを作る。\n",
        "\n",
        "sourceではtoken化の際に`.split(is_split_into_word=True)`を用いている。これは`\\n`を取り除くので、新しい段落を認識させたいときは[別の方法](https://www.kaggle.com/cdeotte/tensorflow-longformer-ner-cv-0-633?scriptVersionId=83615733)を使う必要がある"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "3tp756ZzDoeN"
      },
      "outputs": [],
      "source": [
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len, get_wids):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.get_wids = get_wids    # for validation\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.pull_item(index)\n",
        "        return item\n",
        "\n",
        "    def pull_item(self, index):\n",
        "        # テキストとラベルを取得する\n",
        "        text = self.data.text[index]\n",
        "        word_labels = self.data.entities[index] if not self.get_wids else None\n",
        "\n",
        "        # tokenize\n",
        "        encoding = self.tokenizer(text.split(), is_split_into_words=True, padding=\"max_length\", truncation=True, max_length=self.max_len)\n",
        "        word_ids = encoding.word_ids()\n",
        "\n",
        "        # ターゲットを作る\n",
        "        if not self.get_wids:\n",
        "            previous_word_idx = None\n",
        "            label_ids = []\n",
        "            for word_idx in word_ids:\n",
        "                if word_idx is None:\n",
        "                    label_ids.append(-100)\n",
        "                elif word_idx != previous_word_idx:\n",
        "                    label_ids.append(labels_to_ids[word_labels[word_idx]])\n",
        "                else:\n",
        "                    label_ids.append(labels_to_ids[word_labels[word_idx]])\n",
        "                previous_word_idx = word_idx\n",
        "            encoding[\"labels\"] = label_ids\n",
        "        \n",
        "        # torchTensorに変換\n",
        "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
        "        if self.get_wids:\n",
        "            word_ids2 = [w if w is not None else -1 for w in word_ids]\n",
        "            item[\"wids\"] = torch.as_tensor(word_ids2)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjhZC4ZfDoeN"
      },
      "source": [
        "今回はとりあえず90%:10%のホールドアウト法で行う。(後で5-fold-CVもやります...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcWuJQVXDoeN",
        "outputId": "41588410-08ce-483a-825c-2245cfc88115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 15594 train texts. Now we will split 90:10 for hold-out validation\n"
          ]
        }
      ],
      "source": [
        "IDs = train_label_df.id.unique()\n",
        "print(f\"There are\", len(IDs), \"train texts. Now we will split 90:10 for hold-out validation\")\n",
        "\n",
        "train_idx = np.random.choice(np.arange(len(IDs)), int(0.9*len(IDs)), replace=False)\n",
        "val_idx = np.setdiff1d(np.arange(len(IDs)), train_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5jtSbFQDoeN",
        "outputId": "3223cb3e-d38f-443c-c5c8-904a53826d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Dataset: (15594, 3)\n",
            "Train Dataset: (14034, 2)\n",
            "Val Dataset: (1560, 3)\n"
          ]
        }
      ],
      "source": [
        "data = train_text_df[[\"id\", \"text\", \"entities\"]]\n",
        "train_data = data.loc[data[\"id\"].isin(IDs[train_idx]), [\"text\", \"entities\"]].reset_index(drop=True)\n",
        "val_data = data.loc[data[\"id\"].isin(IDs[val_idx])].reset_index(drop=True)\n",
        "\n",
        "print(f\"Full Dataset: {data.shape}\")\n",
        "print(f\"Train Dataset: {train_data.shape}\")\n",
        "print(f\"Val Dataset: {val_data.shape}\")\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(DOWNLOADED_MODEL_PATH)\n",
        "train_dataset = dataset(train_data, tokenizer, config[\"max_length\"], False)\n",
        "val_dataset = dataset(val_data, tokenizer, config[\"max_length\"], True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGXKAXSXDoeO"
      },
      "source": [
        "### DataLoaderの実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "ruKeZBIiDoeO"
      },
      "outputs": [],
      "source": [
        "# TRAIN DATASET AND VALID DATASET\n",
        "train_params = {'batch_size': config['train_batch_size'], 'shuffle': True, 'num_workers': 2, 'pin_memory':True}\n",
        "\n",
        "val_params = {'batch_size': config['valid_batch_size'], 'shuffle': False, 'num_workers': 2, 'pin_memory':True}\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, **train_params)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, **val_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeHV1zmSDoeO"
      },
      "source": [
        "## 3. Modelの訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SlpALimDoeO"
      },
      "source": [
        "ロードしたモデルは`batch_size=4`, `learning_rate=[5e-5, 5e-5, 5e-6, 5e-6, 5e-7]`で訓練されている。  \n",
        "ちょっと色々サボってる(特にvalidation関連)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ZKZdePRiDoeO"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, optimizer, config, epochs):\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Device:\", device)\n",
        "    model.to(device)\n",
        "\n",
        "    logs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_acc = 0.0\n",
        "        iters = 0\n",
        "\n",
        "        for g in optimizer.param_groups:\n",
        "            g[\"lr\"] = config[\"learning_rates\"][epoch]\n",
        "\n",
        "        phase = \"train\"\n",
        "        if phase == \"train\":\n",
        "            model.train()\n",
        "        with tqdm.tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\") as t:\n",
        "            for batch in t:\n",
        "                iters += 1\n",
        "\n",
        "                ids = batch[\"input_ids\"].to(device, dtype = torch.long)\n",
        "                mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n",
        "                labels = batch[\"labels\"].to(device, dtype=torch.long)\n",
        "\n",
        "                loss, tr_logits = model(input_ids=ids, attention_mask=mask, labels=labels, return_dict=False)\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                # Accuracyの計算\n",
        "                flatted_labels = labels.view(-1)    # [batch_size * seq_len, ]\n",
        "                active_logits = tr_logits.view(-1, model.num_labels)    # [batch_size * seqlen, num_labels]\n",
        "                flatted_predictions = torch.argmax(active_logits, axis=1)   # [batch_size * seq_len, ]\n",
        "\n",
        "                # only compute accuracy at active labels\n",
        "                active_accuracy = labels.view(-1) != -100 # shape (batch_size, seq_len)\n",
        "\n",
        "                labels = torch.masked_select(flatted_labels, active_accuracy)\n",
        "                predictions = torch.masked_select(flatted_predictions, active_accuracy)\n",
        "\n",
        "                tr_acc = sklearn.metrics.accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy())\n",
        "                epoch_acc += tr_acc\n",
        "\n",
        "                # 勾配クリッピング(Normで)\n",
        "                torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=config[\"max_grad_norm\"])\n",
        "\n",
        "                # バックプロパゲーション\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                t.set_postfix_str(f\"Loss: {loss.item():.4f}, Acc: {tr_acc:.4f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"Epoch Loss: {epoch_loss / iters}, Epoch Acc: {epoch_acc / iters}\")\n",
        "        logs.append({\"epoch\": epoch + 1, \"train_loss\": epoch_loss / iters})\n",
        "        df = pd.DataFrame(logs)\n",
        "        df.to_csv(\"/content/logs/log_bigbird_001.csv\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_model = transformers.AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH + \"/config.json\")\n",
        "model = transformers.AutoModelForTokenClassification.from_pretrained(DOWNLOADED_MODEL_PATH + \"/pytorch_model.bin\", config=config_model)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=config[\"learning_rates\"][0])"
      ],
      "metadata": {
        "id": "uiWfoMe-Jlt9"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "torch.cuda.empty_cache()\n",
        "train_model(model, train_dataloader, optimizer, config, config[\"epochs\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxFE0pZIJDhT",
        "outputId": "969fb131-2d8f-46e4-c146-bd590a9c9e30"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 3509/3509 [51:00<00:00,  1.15it/s, Loss: 1.0310, Acc: 0.6197]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.7663042591223862, Epoch Acc: 0.7489396775532061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 3509/3509 [50:58<00:00,  1.15it/s, Loss: 0.2593, Acc: 0.9056]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.6004733942272861, Epoch Acc: 0.7928424021601809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 3509/3509 [50:56<00:00,  1.15it/s, Loss: 0.6050, Acc: 0.7646]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.4668715739116841, Epoch Acc: 0.8358751960630695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5: 100%|██████████| 3509/3509 [50:56<00:00,  1.15it/s, Loss: 0.3531, Acc: 0.8821]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.4368573189393242, Epoch Acc: 0.8452717076901172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/5: 100%|██████████| 3509/3509 [50:58<00:00,  1.15it/s, Loss: 0.2200, Acc: 0.9362]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch Loss: 0.41067998352664664, Epoch Acc: 0.8540176892133634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'/content/model/bigbird_v001.pth')"
      ],
      "metadata": {
        "id": "je6fiizTKTop"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 評価"
      ],
      "metadata": {
        "id": "t2WP2dodJH3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference(model, batch):\n",
        "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "    model.to(device)\n",
        "    ids = batch[\"input_ids\"].to(device)\n",
        "    mask = batch[\"attention_mask\"].to(device)\n",
        "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
        "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy()\n",
        "\n",
        "    predictions = []\n",
        "    for k, text_preds in enumerate(all_preds):\n",
        "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
        "\n",
        "        prediction = []\n",
        "        word_ids = batch[\"wids\"][k].numpy()\n",
        "        previous_word_idx = -1\n",
        "        for idx, word_idx in enumerate(word_ids):\n",
        "            if word_idx == -1:\n",
        "                pass\n",
        "            elif word_idx != previous_word_idx:\n",
        "                prediction.append(token_preds[idx])\n",
        "                previous_word_idx = word_idx\n",
        "        predictions.append(prediction)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "WMSHmDSDKsdp"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(model, dataframe, dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    y_pred2 = []\n",
        "    for batch in tqdm.tqdm(dataloader):\n",
        "        labels = inference(model, batch)\n",
        "        y_pred2.extend(labels)\n",
        "    \n",
        "    final_pred2 = []\n",
        "    for i in range(len(dataframe)):\n",
        "        idx = dataframe.id.values[i]\n",
        "        pred = y_pred2[i]       # \"B\", \"I\"などを残す\n",
        "        j = 0\n",
        "        while j < len(pred):\n",
        "            cls = pred[j]\n",
        "            if cls == \"O\": j += 1\n",
        "            else: cls = cls.replace(\"B\", \"I\")\n",
        "            end = j + 1\n",
        "            while end < len(pred) and pred[end] == cls:\n",
        "                end += 1\n",
        "            \n",
        "            if cls != \"O\" and cls != \"\"and end - j > 7:\n",
        "                final_pred2.append((idx, cls.replace(\"I-\", \"\"), \" \".join(map(str, list(range(j, end))))))\n",
        "            j = end\n",
        "    \n",
        "    oof = pd.DataFrame(final_pred2)\n",
        "    oof.columns = [\"id\", \"class\", \"predictionstring\"]\n",
        "    return oof"
      ],
      "metadata": {
        "id": "nIFabtVWMCh0"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "スコアの算出を行う"
      ],
      "metadata": {
        "id": "YYv5qXWBSioK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_overlap(row):\n",
        "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
        "    set_groundtruth = set(row.predictionstring_gt.split(\" \"))\n",
        "    len_pred = len(set_pred)\n",
        "    len_groundtruth = len(set_groundtruth)\n",
        "    inter = len(set_groundtruth.intersection(set_pred))\n",
        "    overlap1 = inter / len_groundtruth\n",
        "    overlap2 = inter / len_pred\n",
        "    return [overlap1, overlap2]\n",
        "\n",
        "def score_feedback_comp(pred_df, gt_df):\n",
        "    gt_df = gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
        "    pred_df = pred_df[[\"id\", \"class\", \"predictionstring\"]].reset_index(drop=True).copy()\n",
        "    gt_df[\"gt_id\"] = gt_df.index\n",
        "    pred_df[\"pred_id\"] = pred_df.index\n",
        "    \n",
        "    # 1. 全ての正解ラベルと予測を比べる\n",
        "    joined = pred_df.merge(gt_df, left_on=[\"id\", \"class\"], right_on=[\"id\", \"discourse_type\"], how=\"outer\", suffixes=(\"_pred\", \"_gt\"))\n",
        "    joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
        "    joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
        "    joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
        "\n",
        "    # 2. 正解と予測のオーバラップが>=0.5でかつ予測と正解のオーバーラップが>=0.5の時TPとする\n",
        "    joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
        "    joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
        "\n",
        "    joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
        "    joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
        "    tp_pred_ids = joined.query(\"potential_TP\").sort_values(\"max_overlap\", ascending=False).groupby([\"id\", \"predictionstring_gt\"]).first()[\"pred_id\"].values\n",
        "\n",
        "    # 正解ラベルと一致する予測がない時にFN, 予測と一致する正解ラベルがない時にFPとする\n",
        "    fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
        "\n",
        "    matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
        "    unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
        "\n",
        "    TP = len(tp_pred_ids)\n",
        "    FP = len(fp_pred_ids)\n",
        "    FN = len(unmatched_gt_ids)\n",
        "    # mycroF1スコアを計算\n",
        "    my_f1_score = TP / (TP + 0.5 * (FP + FN))\n",
        "    return my_f1_score"
      ],
      "metadata": {
        "id": "pK8yiargMFll"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "スコアを計算して表示してみる"
      ],
      "metadata": {
        "id": "5EuPHr7wSfrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation target\n",
        "val = train_label_df.loc[train_label_df[\"id\"].isin(IDs[val_idx])]\n",
        "\n",
        "config_model = transformers.AutoConfig.from_pretrained(DOWNLOADED_MODEL_PATH + \"/config.json\")\n",
        "model = transformers.AutoModelForTokenClassification.from_pretrained(DOWNLOADED_MODEL_PATH + \"/pytorch_model.bin\", config=config_model)\n",
        "model.load_state_dict(torch.load('/content/model/bigbird_v001.pth'))\n",
        "print('Model loaded.')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "oof = get_predictions(model, val_data, val_dataloader)\n",
        "\n",
        "f1s = []\n",
        "CLASSES = oof[\"class\"].unique()\n",
        "for c in CLASSES:\n",
        "    pred_df = oof.loc[oof[\"class\"] == c].copy()\n",
        "    gt_df = val.loc[val[\"discourse_type\"] == c].copy()\n",
        "    f1 = score_feedback_comp(pred_df, gt_df)\n",
        "    print(c, f1)\n",
        "    f1s.append(f1)\n",
        "print()\n",
        "print(\"Overall:\", np.mean(f1s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVYrpU5AMOX5",
        "outputId": "4d79cea5-e4a1-4dc6-aa8d-6ade35190c04"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 390/390 [01:40<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lead 0.7608267716535433\n",
            "Position 0.6227303295225286\n",
            "Evidence 0.6541214972386992\n",
            "Counterclaim 0.48088360237892946\n",
            "Rebuttal 0.38215102974828374\n",
            "Concluding Statement 0.8070417673455299\n",
            "Claim 0.501190611180406\n",
            "\n",
            "Overall: 0.6012779441525601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TxXB4L4_QzT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "bigbird-baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}